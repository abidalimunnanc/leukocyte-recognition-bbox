{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px; margin:0;font-family:newtimeroman;font-size:300%;text-align:center;border-radius: 30px 10px;overflow:hidden;font-weight:700;background-color:#272643; color:white\">\n",
    "   classification and detection of leukocytes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <img src='https://i.postimg.cc/HxJRDmDz/blood-cancers.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1);border:2px solid #90e0ef; background-color:##e3f6f5 ; ;padding:10px; font-size:130%'>\n",
    "<p style=\"font-size:150%; font-weight:bold\">The Vision Behind CytologIA</p>\n",
    "\n",
    "<p>\n",
    "Hematology, the study of blood diseases, relies heavily on cytology\u0014the examination of blood's cellular components. The Complete Blood Count (CBC) or hemogram is one of the most commonly prescribed analyses, providing both quantitative and qualitative insights into blood cells. Among these cells, leukocytes (white blood cells) play a crucial role in diagnosing and monitoring various hematological conditions.\n",
    "\n",
    "Blood smear analysis under an optical microscope is the gold standard for identifying leukocyte abnormalities but is a time-consuming, expertise-dependent process, leading to diagnostic disparities. Automated systems exist but often struggle with accurate classification of pathological cells, especially in complex cases. Despite advancements, digital microscopes and scanners still rely on manual interpretation, introducing errors and inconsistencies.\n",
    "\n",
    "The CytologIA Data Challenge aims to address these issues by leveraging artificial intelligence to automate the classification of normal and pathological leukocytes. This initiative seeks to enhance diagnostic accuracy, reduce processing times, and ease the workload of medical professionals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='setup'></a> \n",
    "# <span style=\"background-color:#1d3461;background-size: cover;font-family:tahoma;font-size:180%;text-align:center;border-radius:15px 15px; padding:10px; border:solid 2px #09375b\"><span style=\"color:red\"><b> 1 | </b></span><span style=\"color:#ade8f4\"><b> SETUP\n",
    "\n",
    "###### üè† [Tabel of Contents](#tbl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step11'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">1.1 | Install required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ At the first step, Install requred python librasries with <code>pip install</code> command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:13.069970Z",
     "iopub.status.busy": "2025-01-02T06:01:13.069641Z",
     "iopub.status.idle": "2025-01-02T06:01:19.001576Z",
     "shell.execute_reply": "2025-01-02T06:01:19.000135Z",
     "shell.execute_reply.started": "2025-01-02T06:01:13.069920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install -q split-folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step12'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">1.2 | Import required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Then import nesseccary libraries with <code>import</code> command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:19.002908Z",
     "iopub.status.busy": "2025-01-02T06:01:19.002653Z",
     "iopub.status.idle": "2025-01-02T06:01:25.559781Z",
     "shell.execute_reply": "2025-01-02T06:01:25.558831Z",
     "shell.execute_reply.started": "2025-01-02T06:01:19.002887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os                                                       # To work with main operating system commands\n",
    "import gc                                                       # Its a 'Garbage collector' , to freeup spaces\n",
    "import shutil                                                   # To copy and move files\n",
    "import numpy as np                                              # To work with arrays\n",
    "import cv2                                                      # Powerfull library to work with images\n",
    "import random                                                   # To generate random number and random choices\n",
    "import matplotlib.pyplot as plt                                 # To visualization\n",
    "import seaborn as sns                                           # To visualization\n",
    "import splitfolders                                             # To splite images to [train, validation, test]\n",
    "from PIL import Image                                           # To read images\n",
    "from tqdm.notebook import tqdm                                  # Beautifull progress-bar\n",
    "from termcolor import colored                                   # To colorfull output\n",
    "from warnings import filterwarnings                             # to avoid python warnings\n",
    "\n",
    "import torch                                                   # Pytorch framework\n",
    "import torchvision.transforms as transforms                    # to apply some  functions befor create a dataset\n",
    "from torchvision.datasets import ImageFolder                   # To create dataset from images on local drive\n",
    "from torch.utils.data import DataLoader                        # Create DataLoader\n",
    "from torchvision.models import googlenet, GoogLeNet_Weights    # Pre-trained model with its weights\n",
    "import torch.nn as nn                                          # Neural-Networs function\n",
    "from datetime import datetime                                  # To calculate time and duration\n",
    "from sklearn.metrics import confusion_matrix, classification_report     # To calculate and plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step13'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">1.3 | Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Apply above libraries configs to better performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:25.561224Z",
     "iopub.status.busy": "2025-01-02T06:01:25.560776Z",
     "iopub.status.idle": "2025-01-02T06:01:25.565843Z",
     "shell.execute_reply": "2025-01-02T06:01:25.564762Z",
     "shell.execute_reply.started": "2025-01-02T06:01:25.561197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add a style to seaborn plots for better visualization\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# To avoide Python warniongs\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:25.568665Z",
     "iopub.status.busy": "2025-01-02T06:01:25.568365Z",
     "iopub.status.idle": "2025-01-02T06:01:25.583089Z",
     "shell.execute_reply": "2025-01-02T06:01:25.582239Z",
     "shell.execute_reply.started": "2025-01-02T06:01:25.568640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialization values \n",
    "\n",
    "img_size = (128, 128)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:25.585023Z",
     "iopub.status.busy": "2025-01-02T06:01:25.584681Z",
     "iopub.status.idle": "2025-01-02T06:01:25.753340Z",
     "shell.execute_reply": "2025-01-02T06:01:25.751040Z",
     "shell.execute_reply.started": "2025-01-02T06:01:25.584994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Show all colors used in this notebook\n",
    "colors_dark = ['#1d3461', '#eef1fb', '#ade8f4', 'red', 'black', 'orange', 'navy', '#fbf8cc']\n",
    "\n",
    "sns.palplot(colors_dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step14'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">1.4 | Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:25.757049Z",
     "iopub.status.busy": "2025-01-02T06:01:25.756525Z",
     "iopub.status.idle": "2025-01-02T06:01:25.775271Z",
     "shell.execute_reply": "2025-01-02T06:01:25.773171Z",
     "shell.execute_reply.started": "2025-01-02T06:01:25.757002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device.type == 'cuda' :\n",
    "    print(colored(' GPU is available ', 'green', 'on_white', attrs=['bold']))\n",
    "else :\n",
    "    print(colored(' You are using CPU ', 'red', 'on_white', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='data'></a> \n",
    "# <span style=\"background-color:#1d3461;background-size: cover;font-family:tahoma;font-size:180%;text-align:center;border-radius:15px 15px; padding:10px; border:solid 2px #09375b\"><span style=\"color:red\"><b> 2 | </b></span><span style=\"color:#ade8f4\"><b> DATA\n",
    "\n",
    "##### üè† [Tabel of Contents](#tbl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step21'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight:900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">2.1 | Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:25.777512Z",
     "iopub.status.busy": "2025-01-02T06:01:25.777057Z",
     "iopub.status.idle": "2025-01-02T06:01:25.788592Z",
     "shell.execute_reply": "2025-01-02T06:01:25.787119Z",
     "shell.execute_reply.started": "2025-01-02T06:01:25.777473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Path of working directory\n",
    "working_dir = '/home/working/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step22'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">2.2 | Copy images to working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:25.792403Z",
     "iopub.status.busy": "2025-01-02T06:01:25.791925Z",
     "iopub.status.idle": "2025-01-02T06:01:25.806536Z",
     "shell.execute_reply": "2025-01-02T06:01:25.805010Z",
     "shell.execute_reply.started": "2025-01-02T06:01:25.792357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create 'Image' folder in working directory (step 1)\n",
    "Images = os.path.join(working_dir, 'Images')\n",
    "if not os.path.exists(Images) :\n",
    "    os.mkdir(Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T06:01:25.818610Z",
     "iopub.status.busy": "2025-01-02T06:01:25.818373Z",
     "iopub.status.idle": "2025-01-02T06:01:25.834334Z",
     "shell.execute_reply": "2025-01-02T06:01:25.833386Z",
     "shell.execute_reply.started": "2025-01-02T06:01:25.818590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For each class, create a folder in Images folder (step 2)\n",
    "b = os.path.join(Images, 'B')\n",
    "lf = os.path.join(Images, 'LF')\n",
    "pm = os.path.join(Images, 'PM')\n",
    "lam3 = os.path.join(Images, 'LAM3')\n",
    "lyb = os.path.join(Images, 'LyB')\n",
    "pinn = os.path.join(Images, 'PNN')\n",
    "er = os.path.join(Images, 'Er')\n",
    "m = os.path.join(Images, 'M')\n",
    "mo = os.path.join(Images, 'MO')\n",
    "lyabs = os.path.join(Images, 'LY')\n",
    "ss = os.path.join(Images, 'SS')\n",
    "llc = os.path.join(Images, 'LLC')\n",
    "mm = os.path.join(Images, 'MM')\n",
    "ba = os.path.join(Images, 'BA')\n",
    "lgl = os.path.join(Images, 'LGL')\n",
    "lzmg = os.path.join(Images, 'LZMG')\n",
    "lh = os.path.join(Images, 'LH_lyAct')\n",
    "mbl = os.path.join(Images, 'MBL')\n",
    "mob = os.path.join(Images, 'MoB')\n",
    "eo = os.path.join(Images, 'EO')\n",
    "lysee = os.path.join(Images, 'Lysee')\n",
    "thromb = os.path.join(Images, 'Thromb')\n",
    "lm = os.path.join(Images, 'LM')\n",
    "# Create the folders if they don't exist\n",
    "os.makedirs(b, exist_ok=True)\n",
    "os.makedirs(lf, exist_ok=True)\n",
    "os.makedirs(pm, exist_ok=True)\n",
    "os.makedirs(lam3, exist_ok=True)\n",
    "os.makedirs(lyb, exist_ok=True)\n",
    "os.makedirs(pinn, exist_ok=True)\n",
    "os.makedirs(er, exist_ok=True)\n",
    "os.makedirs(m, exist_ok=True)\n",
    "os.makedirs(mo, exist_ok=True)\n",
    "os.makedirs(lyabs, exist_ok=True)\n",
    "os.makedirs(ss, exist_ok=True)\n",
    "os.makedirs(llc, exist_ok=True)\n",
    "os.makedirs(mm, exist_ok=True)\n",
    "os.makedirs(ba, exist_ok=True)\n",
    "os.makedirs(lgl, exist_ok=True)\n",
    "os.makedirs(lzmg, exist_ok=True)\n",
    "os.makedirs(lh, exist_ok=True)\n",
    "os.makedirs(mbl, exist_ok=True)\n",
    "os.makedirs(mob, exist_ok=True)\n",
    "os.makedirs(eo, exist_ok=True)\n",
    "os.makedirs(lysee, exist_ok=True)\n",
    "os.makedirs(thromb, exist_ok=True)\n",
    "os.makedirs(lm, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.228Z",
     "iopub.execute_input": "2025-01-02T06:01:25.835926Z",
     "iopub.status.busy": "2025-01-02T06:01:25.835555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Copy images from dataset to working-dir/Images\n",
    "base_dir = '/home/input/create-images/Images/'\n",
    "for folder in os.listdir(base_dir) :\n",
    "    folder_path = os.path.join(base_dir, folder)\n",
    "    for img in tqdm(os.listdir(folder_path)) :\n",
    "        src = os.path.join(folder_path, img)\n",
    "\n",
    "   \n",
    "        # Use match-case to copy images to the corresponding class folder\n",
    "        match folder:\n",
    "            case 'B':\n",
    "                shutil.copy(src, os.path.join(b, img))\n",
    "            case 'LF':\n",
    "                shutil.copy(src, os.path.join(lf, img))\n",
    "            case 'PM':\n",
    "                shutil.copy(src, os.path.join(pm, img))\n",
    "            case 'LAM3':\n",
    "                shutil.copy(src, os.path.join(lam3, img))\n",
    "            case 'LyB':\n",
    "                shutil.copy(src, os.path.join(lyb, img))\n",
    "            case 'PNN':\n",
    "                shutil.copy(src, os.path.join(pinn, img))\n",
    "            case 'Er':\n",
    "                shutil.copy(src, os.path.join(er, img))\n",
    "            case 'M':\n",
    "                shutil.copy(src, os.path.join(m, img))\n",
    "            case 'MO':\n",
    "                shutil.copy(src, os.path.join(mo, img))\n",
    "            case 'LY':\n",
    "                shutil.copy(src, os.path.join(lyabs, img))\n",
    "            case 'SS':\n",
    "                shutil.copy(src, os.path.join(ss, img))\n",
    "            case 'LLC':\n",
    "                shutil.copy(src, os.path.join(llc, img))\n",
    "            case 'MM':\n",
    "                shutil.copy(src, os.path.join(mm, img))\n",
    "            case 'BA':\n",
    "                shutil.copy(src, os.path.join(ba, img))\n",
    "            case 'LGL':\n",
    "                shutil.copy(src, os.path.join(lgl, img))\n",
    "            case 'LZMG':\n",
    "                shutil.copy(src, os.path.join(lzmg, img))\n",
    "            case 'LH_lyAct':\n",
    "                shutil.copy(src, os.path.join(lh, img))\n",
    "            case 'MBL':\n",
    "                shutil.copy(src, os.path.join(mbl, img))\n",
    "            case 'MoB':\n",
    "                shutil.copy(src, os.path.join(mob, img))\n",
    "            case 'EO':\n",
    "                shutil.copy(src, os.path.join(eo, img))\n",
    "            case 'Lysee':\n",
    "                shutil.copy(src, os.path.join(lysee, img))\n",
    "            case 'Thromb':\n",
    "                shutil.copy(src, os.path.join(thromb, img))\n",
    "            case 'LM':\n",
    "                shutil.copy(src, os.path.join(lm, img))\n",
    "\n",
    "print(colored('All images copied to working directory', 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read and show classes\n",
    "\n",
    "classes = os.listdir(Images)\n",
    "num_classes = len(classes)\n",
    "print(classes)\n",
    "print(f'Number of classes : {num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step23'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">2.3 | Count Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Show a number of samples in each class by countplot ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# classes = ['LF', 'PM', 'B', 'LAM3', 'LyB', 'PNN', 'Er', 'M', 'MO', 'LY', 'SS', 'LLC', 'MM', 'BA', 'LGL', 'LZMG', 'LH_lyAct', 'MBL', 'MoB', 'EO', 'Lysee', 'Thromb', 'LM',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# A variable to store values\n",
    "counts = []\n",
    "\n",
    "# Loop over class names \n",
    "for class_name in classes :\n",
    "    class_path = os.path.join(Images, class_name)\n",
    "    counts.append(len(os.listdir(class_path)))\n",
    "    \n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(13, 12), dpi=400)\n",
    "ax = sns.barplot(x=counts, y=classes, palette='Set1', hue=classes)\n",
    "for i in range(len(classes)) :\n",
    "    ax.bar_label(ax.containers[i])\n",
    "plt.title('Number of images in each class', fontsize=20, fontweight='bold', c='navy')\n",
    "ax.set_xlim(0, 7200)\n",
    "ax.set_xlabel('Counts', fontweight='bold')\n",
    "ax.set_ylabel('Classes', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step24'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">2.4 | Plot Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Now plot some images in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# A loop to iterate below codes for each class\n",
    "for class_name in classes :\n",
    "    # To create a plot with 1 row and 6 column\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 2))\n",
    "    # Define a variable for each class_name's path by joining base_directory and each class_name\n",
    "    class_path = os.path.join(Images, class_name)\n",
    "    # Files is a list of all image names in each folder (class)\n",
    "    files = os.listdir(class_path)\n",
    "    # Choose 6 random image from each class to show in plot\n",
    "    random_images = random.choices(files, k=6)\n",
    "    # A loop to iterate in each 6 random images\n",
    "    for i in range(6) :\n",
    "        # print class_name as suptitle for each class\n",
    "        plt.suptitle(class_name, fontsize=20, fontweight='bold')\n",
    "        # variable img is path of image, by joining class_path and image file name\n",
    "        img = os.path.join(class_path ,random_images[i])\n",
    "       # load image in img variable using keras.utils.load_img(image_path) \n",
    "        img = Image.open(img)\n",
    "        # Plot image\n",
    "        ax[i].imshow(img)\n",
    "        # Turn axis off\n",
    "        ax[i].axis('off')\n",
    "    # Make plots to become nearer to each other\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step25'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">2.5 | Split images to Train-Valid-test folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ In this step, split images to 3 part, <b>Train, Validation and Test</b> by ratio <b>70%, 15%, 15%</b> of whole images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create folder for train and validation and test\n",
    "train_valid = os.path.join(working_dir, 'train_valid')\n",
    "\n",
    "splitfolders.ratio(\n",
    "    input=Images, output=train_valid, seed=42, ratio=(0.7, 0.15, 0.15)\n",
    ")\n",
    "\n",
    "print(colored(f' All images splited to TRAIN / VALIDATION / TEST folders. ', 'white', 'on_green', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Count Images in each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# list of folders\n",
    "folders = os.listdir(train_valid)\n",
    "\n",
    "print(colored('Number of samples in each folder : ', 'green', attrs=['bold']))\n",
    "for folder in folders :\n",
    "    # A variable to store count of images in each part\n",
    "    counts = 0\n",
    "    folder_path = os.path.join(train_valid, folder)\n",
    "    for class_name in os.listdir(folder_path) :\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        counts += len(os.listdir(class_path))\n",
    "    print(colored(f'{folder} : {counts}', 'blue',attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='aug'></a> \n",
    "# <span style=\"background-color:#1d3461;background-size: cover;font-family:tahoma;font-size:180%;text-align:center;border-radius:15px 15px; padding:10px; border:solid 2px #09375b\"><span style=\"color:red\"><b> 3 | </b></span><span style=\"color:#ade8f4\"><b> DATA AUGMENTATIONS\n",
    "\n",
    "###### üè† [Tabel of Contents](#tbl_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Data augmentation is the process of artificially generating new data from existing data, primarily to train new machine learning (ML) models. Data augmentation can address a variety of challenges when training a CNN model, such as limited or imbalanced data, overfitting, and variation and complexity. This technique can increase the size of the dataset and balance the classes by applying different transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Here, choose a sample image to plot with each Augmentation function to represent changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_image = os.path.join(b, '002e2449-4.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step31'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">3.1 | Blure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Blurring an image is a process that makes the image less sharp and reduces its level of detail. It distorts the detail of an image which makes it less clear. The most common use of image blurriness is to remove noise from the image; the other is to get the most detailed part of the image and smooth out the less detailed ones. Image blur is also called image smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 0px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ <b>We use 3 kind of bluring : </b></p>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 1. opencv blur (smoothing) </ul>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 2. Gausian blur </ul>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 3. Meidan blur </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Blure_Filter(img, filter_type =\"blur\", kernel=13):\n",
    "    '''\n",
    "    ### Filtering ###\n",
    "    img: image\n",
    "    filter_type: {blur: blur, gaussian: gaussian, median: median}\n",
    "    '''\n",
    "    if filter_type == \"blur\":\n",
    "        return cv2.blur(img,(kernel,kernel))\n",
    "    \n",
    "    elif filter_type == \"gaussian\":\n",
    "        return cv2.GaussianBlur(img, (kernel, kernel), 0)\n",
    "    \n",
    "    elif filter_type == \"median\":\n",
    "        return cv2.medianBlur(img, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 0px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Represent <b>blur function</b> on sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.25), dpi=400)\n",
    "plt.suptitle('Blured samples', fontweight='bold', fontsize=15)\n",
    "# Original image\n",
    "plt.subplot(1, 4, 1)\n",
    "img = cv2.imread(sample_image)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original', fontweight='bold')\n",
    " # Blurs\n",
    " # List of filters\n",
    "filters = ['blur', 'gaussian', 'median']\n",
    "for filter in filters :\n",
    "    indx = filters.index(filter)\n",
    "    plt.subplot(1, 4, indx+2)\n",
    "    filtered_img = Blure_Filter(img, filter_type=filter, kernel=13)\n",
    "    plt.imshow(filtered_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(filter, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step32'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">3.2 | Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Noise is deliberately altering pixels to be different than what they may should have represented. Old-fashioned films are famous for having speckles black and white pixels present where they should not be. This is noise!  \n",
    "    Noise is one kind of imperfection that can be particularly frustrating for machines versus human understanding. While humans can easily ignore noise (or fit it within appropriate context), algorithms struggle. This is the root of so-called adversarial attacks where small, human-imperceptible pixel changes can dramatically alter a neural network's ability to make an accurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 0px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ <b>We use 3 kind of Noise adding : </b></p>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 1. Gaussian noise </ul>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 2. sp noise </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Add_Noise(img, noise_type=\"gauss\"):\n",
    "    '''\n",
    "    ### Adding Noise ###\n",
    "    img: image\n",
    "    cj_type: {gauss: gaussian, sp: salt & pepper}\n",
    "    '''\n",
    "    if noise_type == \"gauss\": \n",
    "        mean=0\n",
    "        st=0.5\n",
    "        gauss = np.random.normal(mean,st,img.shape)\n",
    "        gauss = gauss.astype('uint8')\n",
    "        image = cv2.add(img,gauss)\n",
    "        return image\n",
    "    \n",
    "    elif noise_type == \"sp\": \n",
    "        prob = 0.01\n",
    "        black = np.array([0, 0, 0], dtype='uint8')\n",
    "        white = np.array([255, 255, 255], dtype='uint8')\n",
    "\n",
    "        probs = np.random.random(img.shape[:2])\n",
    "        img[probs < (prob / 2)] = black\n",
    "        img[probs > 1 - (prob / 2)] = white\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 0px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Represent <b>Noise adding function</b> on sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.75), dpi=400)\n",
    "plt.suptitle('Noised samples', fontweight='bold', fontsize=15)\n",
    "plt.subplot(1, 3, 1)\n",
    "img = cv2.imread(sample_image)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original', fontweight='bold')\n",
    "\n",
    "noises = ['gauss', 'sp']\n",
    "for noise in noises :\n",
    "    indx = noises.index(noise)\n",
    "    plt.subplot(1, 3, indx+2)\n",
    "    noised_img = Add_Noise(img, noise_type=noise)\n",
    "    plt.imshow(noised_img)\n",
    "    plt.axis('off')\n",
    "    plt.title(noise, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step33'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">3.3 | Flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Flipping an image (and its annotations) is a deceivingly simple technique that can improve model performance in substantial ways.\n",
    "\n",
    "Our models are learning what collection of pixels and the relationship between those collections of pixels denote an object is in-frame. But machine learning models (like convolutional neural networks) have a tendency to be quite brittle: they might memorize a specific ordering of pixels describes an object, but if that same object is mirrored across the image, our models may struggle to recognize it.\n",
    "\n",
    "Consider the orientation of your face when you are taking a selfie versus using the backwards lens on your camera: one interpretation may be mirrored while the other is not, yet they are still both your face. This mirroring of orientation is what we call flipping an image.\n",
    "\n",
    "By creating several versions of our images in various orientations, we give our deep learning model more information to learn from without having to go through the time consuming process of collecting and labeling more training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ <b>We use 3 kind of Fliping : </b></p>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 1. X axis </ul>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 2. Y axis </ul>\n",
    "    <ul style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\"> 3. X & Y  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Flip(img, flip_code) :\n",
    "    flipped_img = cv2.flip(img, flip_code)\n",
    "    return flipped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 0px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Represent <b>Flip function</b> on sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.75), dpi=400)\n",
    "plt.suptitle('Flip a sample', fontweight='bold', fontsize=15)\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "img = cv2.imread(sample_image)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "fliped = Flip(img, flip_code=0)\n",
    "plt.imshow(fliped)\n",
    "plt.axis('off')\n",
    "plt.title('Horizontal Flip', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "fliped = Flip(img, flip_code=1)\n",
    "plt.imshow(fliped)\n",
    "plt.axis('off')\n",
    "plt.title('Vertical Flip', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "fliped = Flip(img, flip_code=-1)\n",
    "plt.imshow(fliped)\n",
    "plt.axis('off')\n",
    "plt.title('X&Y Flip', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='step34'></a>\n",
    "## <span style=\"background-color:orange ;background-size: cover;font-family:tahoma;font-size:70%; font-weight: 900; text-align:left;border-radius:25px 25px; padding:10px; border:solid 2px #09375b\"><span style=\"color:navy\">3.4 | Apply Augmantations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "xxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 0px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ OK ! Its time to apply above functions to <b>Train images</b> . Do this by define a function to choose randomly between 3 kind of augs and apply them to images. At last return a <b>dictionary</b> with <b>key</b> of new image name and <b>value</b> of augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Apply_Augmentations(img) :\n",
    "    ''' Apply random choice of augmentation functions on images '''\n",
    "\n",
    "    returned_augs = dict()\n",
    "\n",
    "    AUGS = ['Blure', 'Noise', 'Flip']\n",
    "\n",
    "    # How many of Augs choosen ?\n",
    "    random_num = random.randint(1, 3)\n",
    "    random_choice = random.choices(AUGS, k=random_num)\n",
    "    # To avoid repeatations :\n",
    "    random_choice = list(set(random_choice))\n",
    "\n",
    "    for choice in random_choice :\n",
    "        if choice == 'Blure' :\n",
    "            filters = ['blur', 'gaussian', 'median']\n",
    "            kernels = [5, 7, 9, 11]\n",
    "            random_filter = random.choices(filters, k=1)[0]\n",
    "            random_kernel = random.choices(kernels, k=1)[0]\n",
    "            blured_img =  Blure_Filter(img, filter_type=random_filter, kernel=random_kernel)\n",
    "            new_name = '_blured'\n",
    "            returned_augs[new_name] = blured_img\n",
    "\n",
    "\n",
    "        elif choice == 'Noise' :\n",
    "            noises = ['gauss', 'sp']\n",
    "            random_noise = random.choices(noises, k=1)[0]\n",
    "            noised_img = Add_Noise(img, noise_type=random_noise)\n",
    "            new_name = '_noised'\n",
    "            returned_augs[new_name] = noised_img\n",
    "\n",
    "\n",
    "        elif choice == 'Flip' :\n",
    "            flip_codes = [-1, 0, 1]\n",
    "            random_code = random.choices(flip_codes, k=1)[0]\n",
    "            flipped_img = Flip(img, flip_code=random_code)\n",
    "            if random_code == 0:\n",
    "                new_name = '_fliped_h'\n",
    "                returned_augs[new_name] = flipped_img\n",
    "            elif random_code == 1:\n",
    "                new_name = '_fliped_v'\n",
    "                returned_augs[new_name] = flipped_img\n",
    "            elif random_code == -1:\n",
    "                new_name = '_fliped_xy'\n",
    "                returned_augs[new_name] = flipped_img\n",
    "            \n",
    "    return returned_augs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 0px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Count images in train folder beforeand after of augmentation to find out how many images added to train folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(train_valid, 'train')\n",
    "num_samples_befor_aug = 0\n",
    "\n",
    "for folder in os.listdir(train_dir) :\n",
    "    folder_path = os.path.join(train_dir, folder)\n",
    "    num_samples_befor_aug += len(os.listdir(folder_path))\n",
    "\n",
    "print(colored(f' Number of samples in TRAIN folder befor Augmentation : {num_samples_befor_aug} ', 'black', 'on_white', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for folder in os.listdir(train_dir) :\n",
    "    folder_path = os.path.join(train_dir, folder)\n",
    "    for img_name in tqdm(os.listdir(folder_path)) :\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        returned = Apply_Augmentations(img)\n",
    "\n",
    "        for exported_name, exported_image in returned.items() :\n",
    "            # 1_left.jpg ---TO---> 1_lef_blured.jpg\n",
    "            new_name = img_name.split('.')[0] + exported_name + '.' + img_name.split('.')[-1]\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "        \n",
    "            # Save new image\n",
    "            cv2.imwrite(new_path, exported_image)\n",
    "\n",
    "\n",
    "print(colored(f' Augmentation Completed. ', 'white', 'on_green', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_samples_after_aug = 0\n",
    "\n",
    "for folder in os.listdir(train_dir) :\n",
    "    folder_path = os.path.join(train_dir, folder)\n",
    "    num_samples_after_aug += len(os.listdir(folder_path))\n",
    "\n",
    "print(colored(f' Number of samples  in TRAIN folder after Augmentation : {num_samples_after_aug} ', 'black', 'on_white', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(colored(f' {num_samples_after_aug-num_samples_befor_aug} images added to train directory. ', 'white', 'on_blue', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fbf8cc; padding: 10px 10px 10px 10px; border-radius: 10px; box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.1);border:0px solid #0A2342; text-align:left\">\n",
    "    <p style=\"font-size:16px; font-family:tahoma; line-height: 2em; text-indent: 20px;\">üîµ Torchvision supports common computer vision transformations in the torchvision.transforms and torchvision.transforms.v2 modules. Transforms can be used to transform or augment data for training or inference of different tasks (image classification, detection, segmentation, video classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-02T06:33:44.239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_folder(folder_path):\n",
    "  \"\"\"\n",
    "  Removes a folder and its contents.\n",
    "\n",
    "  Args:\n",
    "    folder_path: The path to the folder to be removed.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"Folder '{folder_path}' and its contents removed successfully.\")\n",
    "  except OSError as e:\n",
    "    print(f\"Error removing folder '{folder_path}': {e}\")\n",
    "\n",
    "# Example usage:\n",
    "folder_to_remove = \"/home/working/Images\" # Replace with the actual path\n",
    "remove_folder(folder_to_remove)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 215574808,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
