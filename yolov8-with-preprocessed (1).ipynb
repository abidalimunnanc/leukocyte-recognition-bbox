{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6f497c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:45:49.440659Z",
     "iopub.status.busy": "2025-01-02T12:45:49.440389Z",
     "iopub.status.idle": "2025-01-02T12:45:54.729856Z",
     "shell.execute_reply": "2025-01-02T12:45:54.728841Z"
    },
    "papermill": {
     "duration": 5.29786,
     "end_time": "2025-01-02T12:45:54.731660",
     "exception": false,
     "start_time": "2025-01-02T12:45:49.433800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m904.4/904.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e793e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:45:54.743551Z",
     "iopub.status.busy": "2025-01-02T12:45:54.743276Z",
     "iopub.status.idle": "2025-01-02T12:47:11.659057Z",
     "shell.execute_reply": "2025-01-02T12:47:11.658061Z"
    },
    "papermill": {
     "duration": 76.923494,
     "end_time": "2025-01-02T12:47:11.660743",
     "exception": false,
     "start_time": "2025-01-02T12:45:54.737249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -q /home/input/image-preprocessed/_output_.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4046c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:47:11.670890Z",
     "iopub.status.busy": "2025-01-02T12:47:11.670660Z",
     "iopub.status.idle": "2025-01-02T12:47:13.080446Z",
     "shell.execute_reply": "2025-01-02T12:47:13.079498Z"
    },
    "papermill": {
     "duration": 1.416812,
     "end_time": "2025-01-02T12:47:13.082406",
     "exception": false,
     "start_time": "2025-01-02T12:47:11.665594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "data_dir = '/home/input/cytol-gia-data/'\n",
    "filepaths = []\n",
    "folds = os.listdir(data_dir)\n",
    "for fold in folds:\n",
    "    foldpath = os.path.join(data_dir, fold)\n",
    "    filelist = os.listdir(foldpath)\n",
    "    if fold in ['ig', 'neutrophil']:\n",
    "        continue\n",
    "    for file in filelist:\n",
    "        fpath = os.path.join(foldpath, file)\n",
    "        \n",
    "        filepaths.append(fpath)\n",
    "       \n",
    "\n",
    "# Concatenate data paths with labels into one dataframe\n",
    "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
    "\n",
    "dff = pd.concat([Fseries], axis= 1)\n",
    "\n",
    "# Extract the file name from the path\n",
    "dff['NAME'] = dff['filepaths'].apply(lambda x: x.split('/')[-1])\n",
    "train = pd.read_csv(\"/home/input/csv-data-clyclo/cytologia-data-1732098640162.csv\")\n",
    "dfcly = pd.merge(left = dff , right = train, on = 'NAME', how = 'inner')\n",
    "# # Assuming 'df' is your pandas DataFrame and 'class' is the column name\n",
    "\n",
    "# # Extract unique class labels\n",
    "# labels = df['class'].unique().tolist()\n",
    "\n",
    "# # Create a dictionary to map labels to integer IDs\n",
    "# label_to_id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# # Map the labels to integer IDs\n",
    "# df['class'] = df['class'].map(label_to_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07bf4fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:47:13.092801Z",
     "iopub.status.busy": "2025-01-02T12:47:13.092510Z",
     "iopub.status.idle": "2025-01-02T12:55:36.224971Z",
     "shell.execute_reply": "2025-01-02T12:55:36.224035Z"
    },
    "papermill": {
     "duration": 503.139493,
     "end_time": "2025-01-02T12:55:36.226744",
     "exception": false,
     "start_time": "2025-01-02T12:47:13.087251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get image size\n",
    "def get_image_size(filepath):\n",
    "    try:\n",
    "        with Image.open(filepath) as img:\n",
    "            return f\"{img.width}x{img.height}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found\"\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Apply the function to the filepaths column\n",
    "dfcly[\"image_size\"] = dfcly[\"filepaths\"].apply(get_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79c5d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:36.237072Z",
     "iopub.status.busy": "2025-01-02T12:55:36.236821Z",
     "iopub.status.idle": "2025-01-02T12:55:36.249262Z",
     "shell.execute_reply": "2025-01-02T12:55:36.248564Z"
    },
    "papermill": {
     "duration": 0.018782,
     "end_time": "2025-01-02T12:55:36.250471",
     "exception": false,
     "start_time": "2025-01-02T12:55:36.231689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfcly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcea73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:36.259974Z",
     "iopub.status.busy": "2025-01-02T12:55:36.259768Z",
     "iopub.status.idle": "2025-01-02T12:55:37.098592Z",
     "shell.execute_reply": "2025-01-02T12:55:37.097778Z"
    },
    "papermill": {
     "duration": 0.845382,
     "end_time": "2025-01-02T12:55:37.100308",
     "exception": false,
     "start_time": "2025-01-02T12:55:36.254926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the main folder\n",
    "main_folder = \"/home/working/train_valid\"\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Walk through each subfolder in train, valid, and test\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_folder = os.path.join(main_folder, split)\n",
    "    \n",
    "    # Ensure the split folder exists\n",
    "    if os.path.exists(split_folder):\n",
    "        for class_name in os.listdir(split_folder):\n",
    "            class_folder = os.path.join(split_folder, class_name)\n",
    "            \n",
    "            # Ensure it's a directory\n",
    "            if os.path.isdir(class_folder):\n",
    "                for image_name in os.listdir(class_folder):\n",
    "                    image_path = os.path.join(class_folder, image_name)\n",
    "                    \n",
    "                    # Add to the data list if it's a file\n",
    "                    if os.path.isfile(image_path):\n",
    "                        # Split the image name into base name and augmentations\n",
    "                        parts = image_name.split(\"_\", 1)\n",
    "                        \n",
    "                        if len(parts) == 2:  # If there's at least one underscore\n",
    "                            base_name = parts[0] + \".jpg\"\n",
    "                            augmented = parts[1].rsplit(\".\", 1)[0]  # Remove file extension from augmentation\n",
    "                            augmented_path = os.path.join(class_folder, image_name)\n",
    "                        else:  # Handle cases with no underscore\n",
    "                            base_name = image_name\n",
    "                            augmented = None\n",
    "                            augmented_path = image_path\n",
    "                        \n",
    "                        # Append the data with file paths\n",
    "                        data.append({\n",
    "                            \"split\": split,\n",
    "                            \"class\": class_name,\n",
    "                            \"NAME\": base_name,\n",
    "                            \"augmented\": augmented,\n",
    "                            \"filepathsaug\": image_path,        # Original image path\n",
    "                     \n",
    "                        })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f411da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:37.110789Z",
     "iopub.status.busy": "2025-01-02T12:55:37.110504Z",
     "iopub.status.idle": "2025-01-02T12:55:37.118356Z",
     "shell.execute_reply": "2025-01-02T12:55:37.117613Z"
    },
    "papermill": {
     "duration": 0.014266,
     "end_time": "2025-01-02T12:55:37.119654",
     "exception": false,
     "start_time": "2025-01-02T12:55:37.105388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: False\n"
     ]
    }
   ],
   "source": [
    "# Check if the specific value exists in the NAME column\n",
    "exists = '6a065480-9_fliped.jpg' in df['NAME'].values\n",
    "print(\"Exists:\", exists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3f86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:37.130045Z",
     "iopub.status.busy": "2025-01-02T12:55:37.129814Z",
     "iopub.status.idle": "2025-01-02T12:55:37.234794Z",
     "shell.execute_reply": "2025-01-02T12:55:37.233926Z"
    },
    "papermill": {
     "duration": 0.111987,
     "end_time": "2025-01-02T12:55:37.236252",
     "exception": false,
     "start_time": "2025-01-02T12:55:37.124265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df,dfcly, on=\"NAME\", how=\"left\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b829d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:37.246768Z",
     "iopub.status.busy": "2025-01-02T12:55:37.246496Z",
     "iopub.status.idle": "2025-01-02T12:55:37.259013Z",
     "shell.execute_reply": "2025-01-02T12:55:37.258329Z"
    },
    "papermill": {
     "duration": 0.019186,
     "end_time": "2025-01-02T12:55:37.260413",
     "exception": false,
     "start_time": "2025-01-02T12:55:37.241227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>class_x</th>\n",
       "      <th>NAME</th>\n",
       "      <th>augmented</th>\n",
       "      <th>filepathsaug</th>\n",
       "      <th>filepaths</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>class_y</th>\n",
       "      <th>image_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [split, class_x, NAME, augmented, filepathsaug, filepaths, x1, y1, x2, y2, class_y, image_size]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['image_size'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e730e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:37.270939Z",
     "iopub.status.busy": "2025-01-02T12:55:37.270728Z",
     "iopub.status.idle": "2025-01-02T12:55:41.345586Z",
     "shell.execute_reply": "2025-01-02T12:55:41.344906Z"
    },
    "papermill": {
     "duration": 4.081745,
     "end_time": "2025-01-02T12:55:41.347017",
     "exception": false,
     "start_time": "2025-01-02T12:55:37.265272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to apply augmentations\n",
    "def adjust_coordinates(row):\n",
    "    # Parse image size\n",
    "    try:\n",
    "        width, height = map(int, row[\"image_size\"].split(\"x\"))\n",
    "    except ValueError:\n",
    "        return row[\"x1\"], row[\"y1\"], row[\"x2\"], row[\"y2\"]  # Return original if size is invalid\n",
    "    \n",
    "    x1, y1, x2, y2 = row[\"x1\"], row[\"y1\"], row[\"x2\"], row[\"y2\"]\n",
    "\n",
    "    if row[\"augmented\"] == \"fliped_h\":  # Horizontal flip\n",
    "        new_x1 = width - x2\n",
    "        new_x2 = width - x1\n",
    "        return new_x1, y1, new_x2, y2\n",
    "    elif row[\"augmented\"] == \"fliped_v\":  # Vertical flip\n",
    "        new_y1 = height - y2\n",
    "        new_y2 = height - y1\n",
    "        return x1, new_y1, x2, new_y2\n",
    "    elif row[\"augmented\"] == \"fliped_xy\":  # Both horizontal and vertical flip\n",
    "        new_x1 = width - x2\n",
    "        new_x2 = width - x1\n",
    "        new_y1 = height - y2\n",
    "        new_y2 = height - y1\n",
    "        return new_x1, new_y1, new_x2, new_y2\n",
    "    else:  # No change for other cases\n",
    "        return x1, y1, x2, y2\n",
    "\n",
    "# Apply the transformation\n",
    "merged_df[[\"new_x1\", \"new_y1\", \"new_x2\", \"new_y2\"]] = merged_df.apply(adjust_coordinates, axis=1, result_type=\"expand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7980405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:41.359567Z",
     "iopub.status.busy": "2025-01-02T12:55:41.359320Z",
     "iopub.status.idle": "2025-01-02T12:55:41.371820Z",
     "shell.execute_reply": "2025-01-02T12:55:41.371218Z"
    },
    "papermill": {
     "duration": 0.019894,
     "end_time": "2025-01-02T12:55:41.372981",
     "exception": false,
     "start_time": "2025-01-02T12:55:41.353087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "finaldf = merged_df[['split', 'NAME','filepathsaug','new_x1', 'new_y1','new_x2', 'new_y2', 'class_x', 'image_size','augmented']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "204bf3e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:41.383749Z",
     "iopub.status.busy": "2025-01-02T12:55:41.383508Z",
     "iopub.status.idle": "2025-01-02T12:55:41.386816Z",
     "shell.execute_reply": "2025-01-02T12:55:41.386250Z"
    },
    "papermill": {
     "duration": 0.009862,
     "end_time": "2025-01-02T12:55:41.388008",
     "exception": false,
     "start_time": "2025-01-02T12:55:41.378146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "finaldf.columns = ['split', 'NAME','filepaths','x1', 'y1','x2', 'y2', 'class', 'image_size','augmented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e909b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:41.398859Z",
     "iopub.status.busy": "2025-01-02T12:55:41.398651Z",
     "iopub.status.idle": "2025-01-02T12:55:41.408418Z",
     "shell.execute_reply": "2025-01-02T12:55:41.407669Z"
    },
    "papermill": {
     "duration": 0.016723,
     "end_time": "2025-01-02T12:55:41.409629",
     "exception": false,
     "start_time": "2025-01-02T12:55:41.392906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e43b361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:41.421092Z",
     "iopub.status.busy": "2025-01-02T12:55:41.420872Z",
     "iopub.status.idle": "2025-01-02T12:55:41.451661Z",
     "shell.execute_reply": "2025-01-02T12:55:41.451007Z"
    },
    "papermill": {
     "duration": 0.038067,
     "end_time": "2025-01-02T12:55:41.453069",
     "exception": false,
     "start_time": "2025-01-02T12:55:41.415002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = finaldf[finaldf['split'] == 'train']\n",
    "val_df = finaldf[finaldf['split'] != 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c569a9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-02T12:55:41.465025Z",
     "iopub.status.busy": "2025-01-02T12:55:41.464816Z",
     "iopub.status.idle": "2025-01-02T12:59:18.529699Z",
     "shell.execute_reply": "2025-01-02T12:59:18.528805Z"
    },
    "papermill": {
     "duration": 217.076281,
     "end_time": "2025-01-02T12:59:18.535546",
     "exception": false,
     "start_time": "2025-01-02T12:55:41.459265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset train preparation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Define class mapping\n",
    "class_mapping = {name: idx for idx, name in enumerate(train_df[\"class\"].unique())}\n",
    "\n",
    "# Output directories\n",
    "output_images_dir = \"/home/working/dataset_new/train/images\"\n",
    "output_labels_dir = \"/home/working/dataset_new/train/labels\"\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Create YOLO-compatible annotations\n",
    "for _, row in train_df.iterrows():\n",
    "    # Load the image to get dimensions\n",
    "    image_path = row[\"filepaths\"]\n",
    "    image = Image.open(image_path)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    # Calculate YOLO format\n",
    "    x_center = ((row[\"x1\"] + row[\"x2\"]) / 2) / image_width\n",
    "    y_center = ((row[\"y1\"] + row[\"y2\"]) / 2) / image_height\n",
    "    width = (row[\"x2\"] - row[\"x1\"]) / image_width\n",
    "    height = (row[\"y2\"] - row[\"y1\"]) / image_height\n",
    "    class_id = class_mapping[row[\"class\"]]\n",
    "\n",
    "    # Save annotation\n",
    "    label_path = os.path.join(output_labels_dir, f\"{os.path.basename(row['filepaths']).split('.')[0]}.txt\")\n",
    "    with open(label_path, \"w\") as f:\n",
    "        f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    # Copy image to output directory\n",
    "    image.save(os.path.join(output_images_dir, os.path.basename(row[\"filepaths\"])))\n",
    "\n",
    "# Save class names\n",
    "with open(\"/home/working/dataset_new/classes.txt\", \"w\") as f:\n",
    "    for class_name in class_mapping:\n",
    "        f.write(f\"{class_name}\\n\")\n",
    "\n",
    "print(\"Dataset train preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb427f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:18.546623Z",
     "iopub.status.busy": "2025-01-02T12:59:18.546371Z",
     "iopub.status.idle": "2025-01-02T12:59:53.218401Z",
     "shell.execute_reply": "2025-01-02T12:59:53.217374Z"
    },
    "papermill": {
     "duration": 34.684262,
     "end_time": "2025-01-02T12:59:53.224926",
     "exception": false,
     "start_time": "2025-01-02T12:59:18.540664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset val preparation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Output directories\n",
    "output_images_dir = \"/home/working/dataset_new/val/images\"\n",
    "output_labels_dir = \"/home/working/dataset_new/val/labels\"\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Create YOLO-compatible annotations\n",
    "for _, row in val_df.iterrows():\n",
    "    # Load the image to get dimensions\n",
    "    image_path = row[\"filepaths\"]\n",
    "    image = Image.open(image_path)\n",
    "    image_width, image_height = image.size\n",
    "\n",
    "    # Calculate YOLO format\n",
    "    x_center = ((row[\"x1\"] + row[\"x2\"]) / 2) / image_width\n",
    "    y_center = ((row[\"y1\"] + row[\"y2\"]) / 2) / image_height\n",
    "    width = (row[\"x2\"] - row[\"x1\"]) / image_width\n",
    "    height = (row[\"y2\"] - row[\"y1\"]) / image_height\n",
    "    class_id = class_mapping[row[\"class\"]]\n",
    "\n",
    "    # Save annotation\n",
    "    label_path = os.path.join(output_labels_dir, f\"{os.path.basename(row['filepaths']).split('.')[0]}.txt\")\n",
    "    with open(label_path, \"w\") as f:\n",
    "        f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    # Copy image to output directory\n",
    "    image.save(os.path.join(output_images_dir, os.path.basename(row[\"filepaths\"])))\n",
    "\n",
    "print(\"Dataset val preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18857b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:53.236230Z",
     "iopub.status.busy": "2025-01-02T12:59:53.235895Z",
     "iopub.status.idle": "2025-01-02T12:59:53.239378Z",
     "shell.execute_reply": "2025-01-02T12:59:53.238572Z"
    },
    "papermill": {
     "duration": 0.01055,
     "end_time": "2025-01-02T12:59:53.240764",
     "exception": false,
     "start_time": "2025-01-02T12:59:53.230214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q split-folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcab1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:53.251872Z",
     "iopub.status.busy": "2025-01-02T12:59:53.251585Z",
     "iopub.status.idle": "2025-01-02T12:59:53.254889Z",
     "shell.execute_reply": "2025-01-02T12:59:53.254180Z"
    },
    "papermill": {
     "duration": 0.010151,
     "end_time": "2025-01-02T12:59:53.256039",
     "exception": false,
     "start_time": "2025-01-02T12:59:53.245888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import splitfolders\n",
    "\n",
    "# # Define input and output directories\n",
    "# input_folder = '/home/working/dataset'\n",
    "# output_folder = '/home/working/dataset_split'\n",
    "\n",
    "# # Split with a ratio\n",
    "# splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(0.95, 0.05), group_prefix=None, move=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9a70e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:53.266881Z",
     "iopub.status.busy": "2025-01-02T12:59:53.266609Z",
     "iopub.status.idle": "2025-01-02T12:59:53.270051Z",
     "shell.execute_reply": "2025-01-02T12:59:53.269300Z"
    },
    "papermill": {
     "duration": 0.010167,
     "end_time": "2025-01-02T12:59:53.271304",
     "exception": false,
     "start_time": "2025-01-02T12:59:53.261137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# labels_dir = '/home/working/dataset_split/val/labels'  # e.g., '/home/working/datasets/dataset_split/train/labels'\n",
    "# # Use glob to find all .txt files in the specified directory\n",
    "# txt_files = glob.glob(os.path.join(labels_dir, '*.txt'))\n",
    "\n",
    "# # Iterate over each file and print its contents\n",
    "# for file_path in txt_files:\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         print(f'Contents of {file_path}:')\n",
    "#         for line in file:\n",
    "#             print(line.strip())\n",
    "#         print('-' * 40)  # Separator between files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49fb7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:53.282244Z",
     "iopub.status.busy": "2025-01-02T12:59:53.281931Z",
     "iopub.status.idle": "2025-01-02T12:59:53.286339Z",
     "shell.execute_reply": "2025-01-02T12:59:53.285596Z"
    },
    "papermill": {
     "duration": 0.0113,
     "end_time": "2025-01-02T12:59:53.287646",
     "exception": false,
     "start_time": "2025-01-02T12:59:53.276346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path to the class.txt file\n",
    "class_file_path = \"/home/working/dataset_new/classes.txt\"\n",
    "\n",
    "# Read the contents of the class.txt file\n",
    "with open(class_file_path, \"r\") as file:\n",
    "    class_list = [line.strip() for line in file.readlines()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d804ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:53.298617Z",
     "iopub.status.busy": "2025-01-02T12:59:53.298333Z",
     "iopub.status.idle": "2025-01-02T12:59:53.304751Z",
     "shell.execute_reply": "2025-01-02T12:59:53.304018Z"
    },
    "papermill": {
     "duration": 0.013257,
     "end_time": "2025-01-02T12:59:53.305984",
     "exception": false,
     "start_time": "2025-01-02T12:59:53.292727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml file has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the classes.txt file\n",
    "class_file_path = \"/home/working/dataset_new/classes.txt\"\n",
    "\n",
    "# Read the contents of the class.txt file\n",
    "with open(class_file_path, \"r\") as file:\n",
    "    class_names = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Define the YAML content with the names dynamically added\n",
    "data_yaml_content = f\"\"\"\n",
    "train: /home/working/dataset_new/train/images\n",
    "val: /home/working/dataset_new/val/images \n",
    "\n",
    "nc: {len(class_names)}  # Number of classes\n",
    "\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "# Write to the YAML file\n",
    "yaml_file_path = \"/home/working/data.yaml\"\n",
    "with open(yaml_file_path, \"w\") as file:\n",
    "    file.write(data_yaml_content)\n",
    "\n",
    "print(\"data.yaml file has been created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eebfa1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:53.318076Z",
     "iopub.status.busy": "2025-01-02T12:59:53.317797Z",
     "iopub.status.idle": "2025-01-02T12:59:53.321198Z",
     "shell.execute_reply": "2025-01-02T12:59:53.320541Z"
    },
    "papermill": {
     "duration": 0.011061,
     "end_time": "2025-01-02T12:59:53.322497",
     "exception": false,
     "start_time": "2025-01-02T12:59:53.311436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define the YAML content\n",
    "# data_yaml_content = \"\"\"\n",
    "# train: /home/working/dataset_new/train/images\n",
    "# val: /home/working/dataset_new/val/images \n",
    "\n",
    "# nc: 23  # Number of classes\n",
    "\n",
    "# names: [\n",
    "#     \"MBL\", \"PM\", \"Er\", \"M\", \"LLC\", \"EO\", \"PNN\", \"LF\", \"BA\", \"MM\", \"LZMG\", \n",
    "#     \"Lysee\", \"LyB\", \"SS\", \"LM\", \"LY\", \"LH_lyAct\", \"B\", \"MoB\", \"LGL\", \"LAM3\", \n",
    "#     \"MO\", \"Thromb\"\n",
    "# ]\n",
    "# \"\"\"\n",
    "\n",
    "# # Write to the YAML file\n",
    "# with open(\"/home/working/data.yaml\", \"w\") as file:\n",
    "#     file.write(data_yaml_content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f300452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T12:59:53.333578Z",
     "iopub.status.busy": "2025-01-02T12:59:53.333294Z",
     "iopub.status.idle": "2025-01-02T21:32:01.100950Z",
     "shell.execute_reply": "2025-01-02T21:32:01.099876Z"
    },
    "papermill": {
     "duration": 30729.120722,
     "end_time": "2025-01-02T21:32:02.448298",
     "exception": false,
     "start_time": "2025-01-02T12:59:53.327576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (pre-trained)\n",
    "model = YOLO(\"yolov8s.pt\")  # Use 'yolov8n.pt' (nano) for speed or 'yolov8s.pt' (small) for better accuracys\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=\"/home/working/data.yaml\",       # Path to your dataset YAML file\n",
    "    epochs=20,              # Number of epochs\n",
    "    batch=64,               # Batch size\n",
    "    imgsz=640,              # Image size\n",
    "    name=\"yolo8_class_bbox\" # Experiment name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af9aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:32:08.158565Z",
     "iopub.status.busy": "2025-01-02T21:32:08.158239Z",
     "iopub.status.idle": "2025-01-02T21:32:08.161473Z",
     "shell.execute_reply": "2025-01-02T21:32:08.160762Z"
    },
    "papermill": {
     "duration": 2.934905,
     "end_time": "2025-01-02T21:32:08.162639",
     "exception": false,
     "start_time": "2025-01-02T21:32:05.227734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Run inference on a single image or a directory of images\n",
    "# results = model.predict(source='/home/working/dataset_split/val/images', save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eed8f8e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T21:32:13.963064Z",
     "iopub.status.busy": "2025-01-02T21:32:13.962773Z",
     "iopub.status.idle": "2025-01-02T21:32:13.965818Z",
     "shell.execute_reply": "2025-01-02T21:32:13.965172Z"
    },
    "papermill": {
     "duration": 2.754214,
     "end_time": "2025-01-02T21:32:13.966943",
     "exception": false,
     "start_time": "2025-01-02T21:32:11.212729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for result in results:\n",
    "#     boxes = result.boxes  # Bounding boxes\n",
    "#     for box in boxes:\n",
    "#         cls = box.cls  # Class index\n",
    "#         conf = box.conf  # Confidence score\n",
    "#         xyxy = box.xyxy  # Bounding box coordinates (x_min, y_min, x_max, y_max)\n",
    "#         print(f'Class: {cls}, Confidence: {conf}, BBox Coordinates: {xyxy}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6383949,
     "sourceId": 10312373,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6384001,
     "sourceId": 10312445,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 215742132,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31593.633332,
   "end_time": "2025-01-02T21:32:20.974441",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-02T12:45:47.341109",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
